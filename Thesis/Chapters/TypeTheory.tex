\chapter{Type Theory}
\label{bg}

Type theory usually refers to a formal system in which terms always have a type. It was initially invented as a foundation of \maths as an alternative to set theory, but it also works well in computer science as a programming language in which we can write certified programs. There are a variety of type theories, like Russell's theory of types, simply typed $\lambda$-calculus, Gödel's System T \cite{gdl:1931} etc. In this thesis we mainly focus on Per Martin-L\"{o}f's intuitionistic type theory. There are also different versions of \mltt and the intensional version (\itt for short) has better computational behaviour and is widely used in programming languages like Agda, Epigram etc. However, several desirable extensional concepts such as functional extensionality and quotient types are not available in \itt. Much research has been done to extend Type Theory with these concepts and new interpretations of type theory are popular and reasonable solutions. \hott is one of them and is also a variant of \mltt and connected to homotopy theory. 


In this chapter we will first briefly introduce the original motivation and evolution of type theory. Then we explain important notions in \mltt, and a list of extensional concepts will be presented. Finally we will describe the programming language Agda which is an implementation of the intensional version of \mltt.


\section{A brief history of Type Theory}

Type theory was first introduced as a refinement of set theory. 
In the 1870s, Georg Cantor and Richard Dedekind founded set theory as a branch of mathematical logic and started to use set theory as a language to describe definitions of various mathematical objects.
In the 1900s, Bertrand Russell discovered a paradox in this system. In naïve set theory, there was no distinction between small sets like the set of natural numbers and "larger" sets like the set of all sets.

\begin{example}[Russell's Paradox]
Let $R$ be the set of all sets which do not contain themselves
$R = \{x ~| ~x \not\in  x\}$.
Then we get a contradiction
$R \in R \iff R \not\in R$.
\end{example}

To avoid this paradox, Russell found that we have to make a distinction between objects, predicates, predicates of predicates, etc. Then Russell proposed the theory of types \cite{rus:1903} where the distinction is internalised by types.
In this simple type theory, each mathematical object is assigned a type. This is done in a hierarchical structure such that "larger" sets and small sets reside in different levels. The "set" of all
sets is no longer a small set, hence the
paradox disappears.

In type theory, The elementary notion \emph{type} plays a similar role to set in set theory, but differs fundamentally. Every term comes with its unique type while in set theory, an element can belong to multiple sets.
For example to introduce a term of natural number $2$, we have to use
a typing judgement $2:\N$, where $\N$ is the set of natural
numbers. The terms are usually constructed using a list of
constructors belonging to a type. Hence an integer term $2 : \Z$ is constructively different to $2:\N$ in type theory.

Following the idea of theories of types, various type theories have been developed.
Simply typed lambda calculus (or Church's theory of types) is the first type theory to introduce functions as primitive objects \cite{sep-type-theory}. It was originally introduced by Alonzo Church in 1940 to avoid the Kleene-Rosser paradox \cite{kleene1935inconsistency} in his untyped lambda calculus.

\begin{example}[Kleene-Rosser paradox]
Suppose we have a function $f = \lambda x . \neg (x ~ x) $, then we can deduce a contradiction by applying it to itself:

$f f = (\lambda x . \neg (x ~ x)) f = \neg (f ~ f)$
\end{example}

Type theory is applied in various fields including computer science. For instance, Haskell was originally based on one of the variants of lambda calculus called System F\footnote{It has evolved into System FC recently.}. 


%There are also other refinements of lambda calculus which is illustrated by the $\lambda$-cube \cite{barendregt1991introduction}.

In 1970s, Per Martin-L\"{o}f \cite{per:71,per:82} developed his
profound intuitionistic type theory (also called \mltt). In this
thesis, we will refer to this system when using the term \emph{Type Theory}.
Type Theory serves as a foundation for constructive mathematics
\cite{martin1984intuitionistic} and can also be used as a functional programming language \cite{DBLP:dblp_journals/tcs/Troelstra99} in
which the evaluation of a well-typed program always terminates \cite{nor:90}. 


From early type theories like that of Russell and Church to modern type theories like de Bruijn's Automath, \mltt and Coquand's Calculus of Constructions (CoC), one of the most important extensions and discoveries is the correspondence between mathematical proofs and computer programs (terms).
Different to set theory whose axioms are based on first-order logic, in modern type theories, intuitionistic logic concepts can be encoded as types through the 
\textbf{Curry-Howard isomorphism (correspondence)}.
The American mathematician Haskell Curry and logician William Alvin
Howard first discovered a correspondence between logic and
computation. They found that propositions can be encoded as types and
proofs can be given by constructing terms (programs). The idea also
relates to the Brouwer–Heyting–Kolmogorov (BHK) interpretation of
intuitionistic logic. For example, a proof of $P \wedge Q$ can be
encoded as the product type $P \times Q$ which contains a proof of $p
: P$ and a proof of $q : Q$. Computationally, implications are
function types, conjunctions are product types, true is the unit type,
false is the empty type etc. 
With dependent types (introduced below), the correspondence extends to predicate logic: the universal and existential quantification correspond to dependent functions and dependent sums. 
This feature turns Type Theory into a programming language where we can formalise proofs as computer programs. We can do computer-aided reasoning about mathematics as well as programs. From a programmer's perspective, it provides a programming language where we can write certified programs.

% also cite http://www.cs.ru.nl/~herman/onderwijs/provingwithCA/paper-lncs.pdf}
% cite http://plato.stanford.edu/entries/type-theory/

Another central concept in \mltt is \textbf{Dependent types}.
A dependent type is a type which depends on values of other types \cite{dtw}. It provides us with the means for defining families of types, for example the family of lists with explicit length called \emph{Vector}, for example $\text{Vec} ~\N ~3$ stands for a three element list of type $\N$. Since the type carries more information, the program specifications can be expressed more accurately. In the example of vectors, we can write a look-up function without "index out of range" problems. It is much simpler to write matrix multiplication with dependent types.


The 1971 version of \mltt \cite{per:71} was impredicative and turned out to be inconsistent due to Girard's paradox \cite{hurkens1995simplification}. It is impredicative in the sense that the universe of types is impredicative. The notion of a \textbf{universe of types} was first used by Martin-L\"{o}f \cite{Martin-Lof-1973} to describe the type of all types and usually denoted as $\mathsf{U}$. An impredicative universe $\mathsf{U}$ has an axiom $\mathsf{U} : \mathsf{U}$.
Starting from the 1972 version \cite{Martin-Lof-1972}, a predicative hierarchy of universes was adopted. Briefly speaking, we start with a universe of small types called $U_0$ and for each $n : \N$ we have $U_n : U_{n+1}$ which forms a cumulative hierarchy of universe. There is a more detailed introduction to the notion of universe written by Erik Palmgren \cite{Palmgren98onuniverses}.


\textbf{Equality} is one of the most contentious topics in Type Theory.
In everyday mathematics the notion of equality is used to describe sameness and taken as granted.
But in Type Theory, we have different notions of equality or equivalence of the terms.
First of all \textbf{definitional equality} (or \textbf{judgemental equality} \cite{martin1984intuitionistic}) denoted $a \equiv b$ is a meta-theoretic equality, which holds when two terms have the same normal forms \cite{nor:90}. Usually it already includes \textbf{computational equality} which is the congruence on terms generated from reduction rules like $\beta$-reduction and $\eta$-expansion.


Since equalities are also propositions, they can be encoded as types.
In the 1972 version of \mltt, there is a type for the equality of natural numbers. It is defined by pattern matching on the two numbers and eventually reduces to unit type or empty type.

In the 1973 version \cite{Martin-Lof-1973}, Martin L\"{o}f introduced an equality type which works for every type, not only for natural numbers. It is called \textbf{identity type} or \textbf{intensional propositional equality} or \textbf{intensional equality}. It is denoted e.g.\ for natural numbers by $\text{Id}_{\N}(a, b)$ or $a =_{\N} b$ (see \autoref{typerule}).


In \itt (ITT or TT$_I$ for short), like the 1973 version or Agda, propositional equality is different from definitional equality. 
The definitional equality is always decidable hence type checking that depends on definitional equality is
decidable as well~\cite{alti:lics99}.



In \ett (ETT or TT$_E$ for short), like the 1980 version \cite{martin1984intuitionistic} or NuPRL, propositional equality is reflected in definitional equality, in other words, two propositionally equal objects are judgementally equal. This is achieved by the \textbf{equality reflection rule}:

\begin{equation}
\label{reflection}
\infer[\text{ID-DEFEQ}]{a \equiv b}{a = b}
\end{equation}

and the \textbf{uniqueness of identity proofs}:

\begin{equation}
\label{ID-Uni}
\infer[\text{ID-UNI}]{p \equiv \text{refl}}{p : a = b}
\end{equation}

Notice that this version of UIP type checks only if we have equality reflection. In some versions of \itt, UIP also holds in other forms, see \Cref{UIPdetail}. 

Due to the addition of equality reflection, type checking becomes undecidable because it has to respect propositional equality which is not decidable in general. For example, the equality reflection rule implies functional extensionality which is not decidable.

\itt is more widely used as a programming language (examples are Coq, Agda, Epigram), because its definitional equality is decidable, hence its type checking is decidable and programs written in it are terminating.

However in \itt, \textbf{extensional concepts} are not available. For example extensional equality of functions, equality of different proofs for the same proposition, and quotient types. Simply adding these concepts as axioms can result in non-canonical objects e.g.\ a term of $\N$ which does not reduce to a numeral (see \Cref{noncanonical}). 


To add these extensional concepts into \itt without losing decidable type checking and canonicity, it seems that types have to be interpreted with more complicated structures than sets.
In the 1990s, some models of Type Theory were proposed such as Hofmann's setoid model, Altenkirch's setoid model, Hofmann and Streicher's groupoid model etc.
The idea of viewing types as groupoids later inspired other mathematicians. For example, Warren \cite{Warren} interprets types as strict \og.

Recently, Voevodsky proposed a new interpretation of intensional \mltt by homotopy-theoretic notions \cite{klv:ssetmodel,voe:06} called \hott (see \Cref{hott}), or univalent foundations of mathematics. 
Type are treated as \emph{spaces} or \emph{higher groupoids}, and terms are \emph{points} of this space, and more generally, functions between types are \emph{continuous maps}. Identity types are \emph{paths}, identity types of identity types are \emph{homotopies}. Although these notions are originally defined with topological notions, in Type Theory they are treated purely homotopically. Equality is internalised as a type so that types have infinite levels of higher structures as \wog.


%It is one of the most important topics in Type Theory.

%Altenkirch and McBride also introduced a variant of \ett called
%\emph{Observational Type Theory}  \cite{alt:06} in which definitional equality is
%decidable and propositional equality is extensional.

%cite http://adam.chlipala.net/cpdt/html/Equality.html


The new interpretation clarifies the nature of equality in Type Theory.
The central idea of \hott is \text{univalence} which can be understood as the property that isomorphic types are equal.
In regular \maths we usually do abstract reasoning on structures which applies to all isomorphic structures, because they can not be distinguished from other objects, hence isomorphic structures can be identified. Univalence can be seen as a formal acceptance of this idea in Type Theory such that we can do abstract reasoning about types. Moreover, many extensional concepts arise from it automatically. The interpretation also helps mathematicians to reason about homotopy theory in programming languages.


To summarise, we present a list of different versions of \mltt:

\begin{enumerate}

\item The 1971 version \cite{per:71} has an impredicative universe, i.e. $\mathsf{U} : \mathsf{U}$, and it turned out to be inconsistent by Girard's paradox.

\item The 1972 version which was published in 1996 \cite{Martin-Lof-1972} abandons the impredicative universe and all later versions are predicative. It does not have an inductive identity type but recursively defines equality for given types e.g.\ $\N$.

\item The 1973 version \cite{Martin-Lof-1973} introduced the inductively defined identity type internalising equality as a type.

\item The 1980 version which is summarised by Giovanni Sambin in 1984 \cite{martin1984intuitionistic} is extensional. It adopts equality reflection, namely an inhabitant of an identity type implies definitionally equality.

\item In the homotopic version \cite{hott}, Vladimir Voevodsky extends it with univalence axiom and provides a homotopic interpretation of it.

\end{enumerate}



\section{The formal system of Type Theory}

The formal type system of Type Theory is given by a list of judgements and a sequence of rules deriving such judgements. We will use the following judgements in this thesis:


\begin{tabular}{l l}
$\Gamma \vdash$ & $\Gamma$  is a well formed context \\
$\Gamma \vdash A$ & $A$  is a well formed type \\
$\Gamma \vdash a : A$ & $a$ is a well typed term of type $A$ in context $\Gamma$ \\
$\delta : \Gamma \Rightarrow \Delta$ & $\delta$ is a substitution from context $\Gamma$ to $\Delta$ \\
\end{tabular}

We also have equality judgements for contexts, types, terms and substitution. For instance,

$\Gamma \vdash a \equiv a' : A$  ~ $a$ and $a'$ are definitionally equal terms of type $A$ in context $\Gamma$

In \itt the judgemental equality $\equiv$ is the same as definitional equality, while propositional equality is usually expressed by an inhabitant of the identity type $\Gamma \vdash p: a =_{A} a' $.


Throughout the thesis, we use the following notational conventions:

\begin{itemize}
\item $\Gamma, \Delta$ for contexts

\item $\gamma, \sigma$ for substitutions

\item $A, B, C$ for types

\item $a, b, c, t, x$ for terms

\item $\defeq$ for definitions

\item $\Set$ or $\Set_0$ for the universe of small types, $\Set_1$, $\Set_2$, ... for higher universes

\end{itemize}

\subsection{Rules for types}\label{typerule}


The rules describe how one can derive the judgements above. They are syntactic rules but the semantic meaning may be revealed from the construction.
The rules for each type former are usually classified as a formation rule, introduction rule, elimination rule, computation rule ($\beta$) and uniqueness rule ($\eta$). Here we will only show the rules for the most important types. The substitution rules are not discussed here but a good reference is \cite{hof:phd}).


First of all, a \textbf{context} is either empty (denoted as $()$) or extended by context comprehension:

\infrule[comprehension]{\Gamma \vdash \andalso \Gamma \vdash A}{\Gamma, x : A \vdash }

In practice, the empty context is usually not written, for example $\vdash \N$.

\textbf{$\Pi$-types} (dependent function type)

\begin{multicols}{2}
\infrule[$\Pi$-form]{\Gamma \vdash A \andalso \Gamma , x : A \vdash B}{\Gamma \vdash \Pi ~(x:A) ~B }
\columnbreak
\infrule[$\Pi$-intro]{\Gamma , x : A \vdash b : B}{\Gamma \vdash \lambda (x:A). b : \Pi ~(x:A) ~B }
\end{multicols}

\infrule[$\Pi$-elim]{\Gamma \vdash f : \Pi ~ (x:A)~B \andalso \Gamma \vdash a : A}{\Gamma \vdash f(a): B[a/x]}

In the expressions like $\lambda (x:A).b$, $\lambda$ binds the free occurrences of $x$ in $b$.
In the expressions like $B[a/x]$ or $b[a/x]$ we do a \emph{standard substitution} in type $B$ or term $b$ that replaces free occurences of $x$ by $a$. We will use a shorthand notation for substitution later, for example, $C[a,b]$ for $C[a/x,b/y]$ where the order of arguments corresponds to the order in the typing rule.

In this thesis, we also adopt a generalised arrow notation to write $\Pi$-types, for example $(x : A) \to B$, and their terms $\lambda (x: A) \to b$.

\begin{multicols}{2}
computation rule
$$(\lambda (x:A) \to b)(a) \equiv b[a]$$

\columnbreak

uniqueness rule
$$f \equiv \lambda x \to f(x) $$
\end{multicols}

\textbf{$\Sigma$-types} (dependent product type)


\begin{multicols}{2}
\infrule[$\Sigma$-form]{\Gamma \vdash A \andalso \Gamma , x : A \vdash B}{\Gamma \vdash \Sigma ~A ~B }
\columnbreak
\infrule[$\Sigma$-intro]{\Gamma \vdash a : A \andalso \Gamma \vdash b : B[a]}{\Gamma \vdash (a,b) : \Sigma ~A ~B}
\end{multicols}

There are two ways to eliminate a term of a $\Sigma$-type:

\begin{multicols}{2}
\infrule[$\Sigma$-proj$_1$]{\Gamma \vdash t : \Sigma ~ A ~B}{\pi_1(t) : A}
\columnbreak
\infrule[$\Sigma$-proj$_2$]{\Gamma \vdash t : \Sigma ~ A ~B}{\pi_2(t) : B[\pi_1(t)]}
\end{multicols}

The computation rules are 

$$\pi_1 ~(a,b) \equiv a~ \text{and} ~ \pi_2 ~(a,b) \equiv b$$

and the uniqueness rule is

$$t \equiv (\pi_1 ~t, \pi_2 ~t).$$

\textbf{Identity type}

The identity type is a notion of intensional propositional equality given by the following rules:

\begin{multicols}{2}
\infrule[=-form]{\Gamma \vdash A \andalso \Gamma \vdash a : A, \andalso \Gamma \vdash a' : A}{\Gamma \vdash a =_A a'}
\columnbreak
\infrule[=-intro]{\Gamma \vdash a : A}{\Gamma \vdash \refl{} (a) : a =_A a}
\end{multicols}

We use  $a =_{A} a'$ instead of $\text{Id}_A(a, a')$ to denote the identity type, or simply $a = a'$.

\infrule[$\J$]{\Gamma , x : A, y : A, p : x =_A y \vdash C  \andalso \Gamma , x : A \vdash t(x) : C[x,x,refl(x)] \\ \andalso \Gamma \vdash a: A \andalso \Gamma \vdash a': A \andalso \Gamma \vdash p : a =_A a'}{\Gamma \vdash \J (t,a,a',p): C[a',a',p]}

Its computation rule is

$$\J (t,a,a,r(a)) \equiv t(a).$$

The \emph{uniqueness of identity proofs} (UIP) is not a consequence of $\J$ but another eliminator called $\K$ (see \Cref{UIPdetail}).

\begin{definition}\label{subst}
\textbf{"subst" function}.

Given a type family $B : A \to \Set$, and $p : a =_A a'$, we can easily define a function of type $B(a) \to B(a')$ by applying $\J$:

Let 

$$C(x,y,p) \defeq B(x) \to B(y)$$

$$t(x) \defeq \text{id}$$

Thus,

$$\mathsf{subst}(B,p) \defeq : \J (t,a,a',p) : B(a) \to B(a')$$

For simplicity, if we have a term $b : B(a)$, we write the result of $\mathsf{subst}$ as $\mathsf{subst}(B,p,b) : B(a')$.
\end{definition}

\textbf{Unit type}


\begin{multicols}{2}
\infrule[$\top$-form]{}{\vdash \top}
\columnbreak
\infrule[$\top$-intro]{}{\vdash \textsf{tt} : \top}
\end{multicols}

\infrule[$\top$-elim]{\Gamma ,x : \top \vdash A \andalso \Gamma \vdash t : A[\textsf{tt}] }{ \vdash t : A}


\textbf{Empty type}


\begin{multicols}{2}
\infrule[$\bot$-form]{}{\vdash \bot}

\columnbreak

\infrule[$\bot$-elim]{\Gamma \vdash A \andalso e: \bot}{\Gamma \vdash \text{abort}(e) : A}

\end{multicols}

There is no term of the empty type so there is no introduction rule.

\textbf{Universe types}


\begin{multicols}{2}

\infrule[$\mathsf{U}$-form]{}{\Gamma \vdash \mathsf{U}}

\columnbreak

\infrule[$\mathsf{U}$-El]{\Gamma \vdash \hat{A} : \mathsf{U}}{\Gamma \vdash \mathsf{El}({\hat{A}})}

\end{multicols}


\begin{multicols}{2}


\infrule[$\mathsf{U}$-intro-nat]{}{\Gamma \vdash nat : \mathsf{U}}

\columnbreak

\infrule[$\mathsf{U}$-intro-arr]{\Gamma \vdash {\hat{A}}, {\hat{B}} : \mathsf{U} }{\Gamma \vdash arr(\hat{A},\hat{B}) : \mathsf{U}}


\end{multicols}

The computation rules are

\begin{align*}
\mathsf{El}(nat) &\equiv \N \\
\mathsf{El}(arr(\hat{A},\hat{B})) &\equiv \mathsf{El}(\hat{A}) \to \mathsf{El}(\hat{B})
\end{align*}

The notation of $\hat{A}$ indicates that it is a code for a type (a term of $\mathsf{U}$) rather than a type.


\textbf{Inductive types}\label{df:inductivetypes}

Inductive types are a self-referential schema to define new types by specifying a collection of \emph{constructors} which can be constants or functions.

The formation and introduction rules are enough to build a type inductively. Natural numbers $\N : \Set$ can be defined as follows:

\begin{itemize}
\item $0 : \N$
\item $\text{suc} : \N \rightarrow \N$
\end{itemize}

The terms are freely generated by a finite list of these constructors, for instance, $\text{suc} ~(\text{suc} ~0)$ stands for natural number $2$. They are similar to data structures in programming languages, and most implementations of Type Theory have inductive types along with structural recursion to eliminate from them.



\textbf{Coinductive types}\label{df:coinductivetypes}

Coinductive types can be seen as infinitary extensions of inductive types \cite{DBLP:journals/tcs/Capretta11}. A typical example of an infinite data structure is the type of streams (or infinite lists). A stream of type $A$ has one constructor:

\begin{itemize}
\item $\text{cons} : A \to \text{Stream} ~A \to \text{Stream} ~A$
\end{itemize}

An object of it can be destructed into an element of $A$ and again a stream of $A$, in other words, it can continuously produce terms of type $A$. To manipulate coinductive types, we usually use corecursion which can be non-terminating but has to be productive. For example a stream of $0$s can be constructed by:

$$\text{zeros} = \text{cons}(0,\text{zeros})$$

Note that the manner of using coinductive types varies in different languages.  For further reference, one can read \cite{DBLP:journals/tcs/Capretta11}.

\section{An implementation of Type Theory: Agda}

Agda is a dependently typed functional programming language which is based on the intensional version
of \mltt \cite{agdawiki:main}. 

\begin{itemize}

\item \textit{Functional programming language}. As the name indicates, functional programming languages emphasise the application of functions rather than changing data in imperative style like C{}\verb!++! and Java. The basis of functional programming is the lambda calculus. There are several generations of functional programming languages, for example Lisp, Erlang, Haskell, SML etc. 
Agda is a pure functional programming language which offers lazy evaluation (see \autoref{features}) like Haskell. In a pure language, side effects are eliminated which means we ensure that the result will be the same no matter how many times we input the same data. 
%Most of the applications of them are currently in the academic fields, however as the functional programming developed, more applications will be explored.

\item \textit{Implementing Per Martin-L\"{o}f Type Theory}. Agda is based on the Curry-Howard isomorphism \cite{aboa}. It means that we can reason about \maths and programs by constructing proofs as programs. In many languages the correctness of programs has to be verified on the meta-level. However in Agda we verify programs within the same language, and express specifications and  programs at the same time, as Nordström et al. \cite{nor:90} pointed out.


\item \textit{Dependent types}. 
As a feature of Martin-L\"{o}f intuitionistic Type Theory, types in Agda can depend on values of other types \cite{dtw}, which is different from Haskell and other Hindley-Milner style languages where types and values are distinct. It not only helps encoding quantifiers but also allows writing very expressive types which can be seen as program specifications resulting in programs being less error-prone.
For example, in Agda the type of matrices comes with accurate size e.g.\ $\text{Matrix}~3~4$. Thus we can specify the multiplication of matrices as a function of type $\text{Matrix}~m~n \to \text{Matrix}~n~p \to \text{Matrix}~m~p$ where $m,n,p : \N$. 
\end{itemize}


\subsection{Features}\label{features}

Some features of being a functional programming language make theorem proving easier,

\begin{itemize}
\item \textit{Pattern matching}. The mechanism for dependently typed pattern matching is very powerful \cite{alti:pisigma-new}. Pattern matching is a more intuitive way to use terms than eliminators. For example, to prove symmetry of identity by pattern matching on a term of identity type, the only possible case $\mathsf{refl}$ exists when $a$ and $b$ are identical, hence the result type becomes $\AgdaBound{a} \AgdaDatatype{≡} \AgdaBound{a}$.

\begin{code}
\\
\>\AgdaFunction{symm} \AgdaSymbol{:} \AgdaSymbol{\{}\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaSymbol{\}\{}\AgdaBound{a} \AgdaBound{b} \AgdaSymbol{:} \AgdaBound{A}\AgdaSymbol{\}} \AgdaSymbol{→} \AgdaBound{a} \AgdaDatatype{≡} \AgdaBound{b} \AgdaSymbol{→} \AgdaBound{b} \AgdaDatatype{≡} \AgdaBound{a}\<%
\\
\>\AgdaFunction{symm} \AgdaInductiveConstructor{refl} \AgdaSymbol{=} \AgdaInductiveConstructor{refl}\<%
\\
\end{code}

Using the eliminator $\J$ is more tedious:

\begin{code}\label{symmetry}
\\
\>\AgdaFunction{symm'} \AgdaSymbol{:} \AgdaSymbol{\{}\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaSymbol{\}\{}\AgdaBound{a} \AgdaBound{b} \AgdaSymbol{:} \AgdaBound{A}\AgdaSymbol{\}} \AgdaSymbol{→} \AgdaBound{a} \AgdaDatatype{≡} \AgdaBound{b} \AgdaSymbol{→} \AgdaBound{b} \AgdaDatatype{≡} \AgdaBound{a}\<%
\\
\>\AgdaFunction{symm'} \AgdaSymbol{=} \AgdaFunction{J} \AgdaSymbol{(λ} \AgdaBound{a} \AgdaBound{b} \AgdaBound{\_} \AgdaSymbol{→} \AgdaBound{b} \AgdaDatatype{≡} \AgdaBound{a}\AgdaSymbol{)} \AgdaSymbol{(λ} \AgdaBound{\_} \AgdaSymbol{→} \AgdaInductiveConstructor{refl}\AgdaSymbol{)} \AgdaSymbol{\_} \AgdaSymbol{\_}\<%
\\
\end{code}

\item \textit{Inductive \& Recursive definition}. In Agda, types are often defined inductively, for example, natural numbers are defined as:

\begin{code}\>\<%
\>\AgdaKeyword{data} \AgdaDatatype{ℕ} \AgdaSymbol{:} \AgdaPrimitiveType{Set} \AgdaKeyword{where}\<%
\\
\>[0]\AgdaIndent{2}{}\<[2]%
\>[2]\AgdaInductiveConstructor{zero} \AgdaSymbol{:} \AgdaDatatype{ℕ}\<%
\\
\>[0]\AgdaIndent{2}{}\<[2]%
\>[2]\AgdaInductiveConstructor{suc} \<[7]%
\>[7]\AgdaSymbol{:} \AgdaSymbol{(}\AgdaBound{n} \AgdaSymbol{:} \AgdaDatatype{ℕ}\AgdaSymbol{)} \AgdaSymbol{→} \AgdaDatatype{ℕ}\<%
\>\<\end{code}

Functions on inductive types can be defined recursively using pattern matching. For example addition on natural numbers is defined as:

\begin{code}\>\<%
\\
\>\AgdaFunction{\_+\_} \AgdaSymbol{:} \AgdaDatatype{ℕ} \AgdaSymbol{→} \AgdaDatatype{ℕ} \AgdaSymbol{→} \AgdaDatatype{ℕ}\<%
\\
\>\AgdaInductiveConstructor{zero} \<[6]%
\>[6]\AgdaFunction{+} \AgdaBound{n} \AgdaSymbol{=} \AgdaBound{n}\<%
\\
\>\AgdaInductiveConstructor{suc} \AgdaBound{m} \AgdaFunction{+} \AgdaBound{n} \AgdaSymbol{=} \AgdaInductiveConstructor{suc} \AgdaSymbol{(}\AgdaBound{m} \AgdaFunction{+} \AgdaBound{n}\AgdaSymbol{)}\<%
\>\<\end{code}

It also enables programmers to prove propositions in the same manner as mathematical induction and case analysis.

\item \textit{Lazy evaluation}. As a pure functional programming language, Agda offers lazy evaluation which eliminates unnecessary operation to delay a computation until we need its result. It is often used to handle infinite data structures \cite{wiki:Lazy_evaluation}.

\end{itemize}

Compared to other programming languages like Haskell, there is an interactive Emacs interface which provides a few important functions.

\begin{itemize}
\item \textit{Type checker}. The type checker is an essential part of Agda. It will detect type mismatch problems when some code is loaded into Agda.
It also includes a coverage checker and a termination checker.
The \emph{coverage checker} ensures that the patterns cover all possible cases so that programs do not crash \cite{aboa}.
The \emph{termination checker} ensures that all Agda functions terminate \cite{tutorial}.  As a theorem prover, the type checker ensures that the proof is complete and not defined by itself.

 
\item \textit{Interactive interface}. Agda has an Emacs-based interface for interactively writing and verifying proofs.
As long as code is loaded, namely type checked, the code will be highlighted and problematic code is coloured by red for non-termination and yellow for not inferable implicit arguments.
In the interactive Emacs interface, there are a few convenient short-cut keys, for example showing the context, refining the goal with a partial program, navigating to definitions of some functions or types. The refinement function helps us incrementally build programs with explicit context information. Thus type signatures are usually essential for accurate information.
The code navigation alleviates a great deal of work of programmers to look up the documentation.


\item \textit{Unicode and mixfix support}. In Haskell and Coq, unicode support is not an essential part. The name of operations can be very complicated without enough symbols. Agda handles unicode characters and is able to handle unicode symbols like $\beta$, $\forall$ and $\exists$. 

It also uses a flexible mixfix notation where the positions of arguments are indicated by underscores.
E.g.\ $\_⇒\_$ is one identifier which can be applied to two arguments as
in $A ⇒ B$.

In the following type signature of the commutativity theorem for addition of natural numbers, $\AgdaDatatype{ℕ}$ and $\AgdaDatatype{≡}$ are unicode characters, $\AgdaFunction{+}$ and $\AgdaDatatype{≡}$ are mixfix operators. 

\begin{code}%
\>\AgdaFunction{comm} \AgdaSymbol{:} \AgdaSymbol{∀} \AgdaSymbol{(}\AgdaBound{a} \AgdaBound{b} \AgdaSymbol{:} \AgdaDatatype{ℕ}\AgdaSymbol{)} \AgdaSymbol{→} \AgdaBound{a} \AgdaFunction{+} \AgdaBound{b} \AgdaDatatype{≡} \AgdaBound{b} \AgdaFunction{+} \AgdaBound{a}\<%
\end{code}

Note that in Agda $\AgdaDatatype{≡}$ is used for the identity type. See discussion in \Cref{agdaconventions}.


%Note that $\AgdaFunction{+}$ is not primitive operator in Agda, and identity types are denoted as $\AgdaBound{a} \AgdaDatatype{≡} \AgdaBound{b}$ because $=$ is reserved for function definitions. 

Unicode symbols and the mixfix notation improves the readability and provides familiar symbols used in \maths.
Interestingly we could use some characters of other languages to define functions such as Chinese characters.

\item \textit{Implicit arguments and wildcards}. Sometimes it is unnecessary to state an argument. If an argument can be inferred from other arguments we can mark it as implicit with curly brackets. For example, whenever we feed an argument $a$ to function $\AgdaFunction{id}$,  the implicit type $A$ is inferable:

\begin{code}\>\<%
\\
\>\AgdaFunction{id} \AgdaSymbol{:} \AgdaSymbol{\{}\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaSymbol{\}} \AgdaSymbol{→} \AgdaBound{A} \AgdaSymbol{→} \AgdaBound{A}\<%
\\
\>\AgdaFunction{id} \AgdaBound{a} \AgdaSymbol{=} \AgdaBound{a}\<%
\>\<\end{code}

If an explicit argument can be automatically inferred or not used in the program definition, we can replace it with underscores as wildcards (see the code on $\AgdaFunction{symm'}$ above in \Cref{symmetry}).

In practice, the use of implicit arguments and wildcards makes the code more readable.


\item \textit{Module system}. The mechanism of parametrised modules makes it possible to define generic operations and prove a whole set of generic properties.


\item \textit{Coinduction}. We can define coinductive types such as streams in Agda:

\begin{code}
\>\AgdaKeyword{data} \AgdaDatatype{Stream} \AgdaSymbol{(}\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaSymbol{)} \AgdaSymbol{:} \AgdaPrimitiveType{Set} \AgdaKeyword{where}\<%
\\
\>[0]\AgdaIndent{2}{}\<[2]%
\>[2]\AgdaInductiveConstructor{\_∷\_} \AgdaSymbol{:} \AgdaBound{A} \AgdaSymbol{→} \AgdaDatatype{∞} \AgdaSymbol{(}\AgdaDatatype{Stream} \AgdaBound{A}\AgdaSymbol{)} \AgdaSymbol{→} \AgdaDatatype{Stream} \AgdaBound{A}\<%
\end{code}

The coinductive occurrences in the definition are labelled with the delay operator $\infty$. To manipulate coinductive types and more generally mixed inductive/coinductive types \cite{txa:mpc2010g}, we use the delay operation $\sharp$ and the force operation $\flat$ defined in module \textbf{Coinduction}:

\begin{align*}
\sharp &: \forall \{A : \Set\} \to A \to \infty~ A \\
\flat  &: \forall \{A : \Set\} \to \infty ~A \to A
\end{align*}


As an example, to add one to every object of a stream of natural numbers, we define the function using corecursion as follows:

\begin{code}
\>\AgdaFunction{plus1} \AgdaSymbol{:} \AgdaDatatype{Stream} \AgdaDatatype{ℕ} \AgdaSymbol{→} \AgdaDatatype{Stream} \AgdaDatatype{ℕ}\<%
\\
\>\AgdaFunction{plus1} \AgdaSymbol{(}\AgdaBound{n} \AgdaInductiveConstructor{::} \AgdaBound{ns}\AgdaSymbol{)} \AgdaSymbol{=} \AgdaInductiveConstructor{suc} \AgdaBound{n} \AgdaInductiveConstructor{::} \AgdaCoinductiveConstructor{♯} \AgdaFunction{plus1} \AgdaSymbol{(}\AgdaFunction{♭} \AgdaBound{ns}\AgdaSymbol{)}\<%
\end{code}

\item \textit{Ring solver}. Compared to Coq, Agda has no tactics providing automated proof generation although it has a ring solver which plays a similar role to the tactic \textit{ring}. It is easy to use for people who are familiar with constructive \maths.
\end{itemize} 


\subsection{Agda conventions}\label{agdaconventions}

The syntax of Agda has some similarities to Haskell or \mltt, but there are some important differences which may cause confusion:

\begin{itemize}

\item The meaning of $\AgdaSymbol{=}$ is swapped with the one of $\AgdaDatatype{≡}$. The symbol "$\AgdaSymbol{=}$" is reserved for function definition following the convention in programming languages. The congruence symbol "$\AgdaDatatype{≡}$'' is used for the identity type. This is inconsistent with our conventional choice of symbols in articles.

\item $\AgdaSymbol{:}$ is used for typing judgement, for example $\AgdaFunction{a} \AgdaSymbol{:} \AgdaDatatype{A}$, while double colon $\AgdaSymbol{::}$ is the \emph{cons} constructor for list.
It is different from the usual notational conventions in Haskell.

\item The universe of small types is $\Set_{0}$ or $\Set$ instead of $\Type$, even though it is not a set in set-theoretical sense.
%We will follow the \textbf{typical ambiguity} in this thesis which says that we write $\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}$ for $\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set} \AgdaBound{a}$ and $\AgdaPrimitiveType{Set} \AgdaSymbol{:} \AgdaPrimitiveType{Set}$ which stands for $\AgdaPrimitiveType{Set}\AgdaBound{i} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaBound{(i+1)}$.

\item The universe of propositions $\Prop$ ($\Prop \subset \Set$) is not available. Propositions are also in the universe $\Set$. If necessary, we will postulate the proof-irrelevance property for a given proposition $P : \Set$.

\item Agda has a more liberal way to define $\Pi$-types. $\Pi$-types are written in a generalized
arrow notation $(x : A) → B$ for $\Pi x:A.B$. Together with implicit arguments, it is valid to write a type signature as $\forall\{A : \Set \}(x : A) \to \{y : A\} \to x \equiv y$.


\item $\Sigma$-types are defined in Agda standard library. There are also generalised $\Sigma$-types called \emph{dependent record types} which can be defined with keyword \textbf{record}.


\item In Agda, we use the Paulin-Mohring style identity type:

\begin{code}
\\
\>\AgdaKeyword{data} \AgdaDatatype{\_≡\_} \AgdaSymbol{\{}\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaSymbol{\}} \AgdaSymbol{(}\AgdaBound{x} \AgdaSymbol{:} \AgdaBound{A}\AgdaSymbol{)} \AgdaSymbol{:} \AgdaBound{A} \AgdaSymbol{→} \AgdaPrimitiveType{Set} \AgdaKeyword{where}\<%
\\
\>[0]\AgdaIndent{2}{}\<[2]%
\>[2]\AgdaInductiveConstructor{refl} \AgdaSymbol{:} \AgdaBound{x} \AgdaDatatype{≡} \AgdaBound{x}\<%
\\
\end{code}
It is parametrised by the left side of the identity and is equivalent to the original version.
\end{itemize}



\section{Extensional concepts}
\label{extensionality}



In \itt, extensional (propositional) equality is not captured by the identity type which is intensional.

However, the identity type in intensional type theory is not powerful enough for formalisation of mathematics and program development. Notably, it does not identify pointwise equal functions (functional extensionality) and provides no means of redefining equality on a type as a given relation, i.e. quotient types. We call such capabilities extensional concepts.



Objects are extensionally equal if they have the same \emph{observable} behaviour. In other words, they can be substituted by one another in any context without changing the output of the program. For example point-wise equal functions, different proofs of the same proposition etc. Extensional (propositional) equality is not captured by the identity type which is intensional.
Thus in the traditional formulation of \itt, extensionality and some other related features of propositional equality like quotient types are not available. These \emph{extensional concepts} have been summarised and comprehensively studied by Martin Hofmann \cite{hof:phd}; a list of them are given as follows:


\begin{itemize}

\item \textbf{Functional extensionality} 


\infrule[fun-ext]{\Gamma \vdash A \andalso \Gamma , x : A \vdash B \andalso \Gamma \vdash f, g : (x : A)  \to B(x) \\ \Gamma, a : A \vdash p: f(a) = g(a)}{\Gamma \vdash \text{ext}(a,p): f = g}

 If two (dependent) functions are point-wise propositionally equal, they are (extensionally) propositionally equal. This is called
functional extensionality which is not inhabited in the traditional formulation of \itt \cite{alti:lics99}.
For example, two functions of type $\N \to \N$, $\lambda n \to n$ and $\lambda n \to n + 0$ are point-wise propositionally equal, but the intensional propositional equality of them is not inhabited due to the fact that $n + 0$ does not reduce to $n$ (assuming that $\_+\_$ is defined as the one in \Cref{features}).

%given two types $A$ and $B$, and two functions $f,\,g\,\colon A \to B$,

%\[Ext = \forall\, x\colon A, f x = g x \to f = g\]
In \ett, functional extensionality is inhabited:
\begin{theorem}\label{prf:ertofe}
Functional extensionality is derivable from the equality reflection rule.
\end{theorem}
\begin{proof}
Suppose $\Gamma , a : A \vdash p : f \,a = g \,a$, with the reflection rule we have $\Gamma ,a : A \vdash f \,a \equiv g \,a$.
Then using $\xi$-rule, we know that $\Gamma \vdash \lambda a . f \,a \equiv \lambda a . g \,a$.
From the $\eta$-rule of $\Pi$-types and the transitivity of $\equiv$, we know that $\Gamma \vdash f \equiv g$. Finally we can conclude that $\Gamma \vdash \text{refl}(f) : f = g$.
\end{proof}

In \itt, since propositional equality is not identified with definitional equality, it is not inhabited.
If we postulate $\text{FUN-EXT}$, the $\N$-canonicity property by Hofmann (see Definition 2.1.9 in \cite{hof:phd}) of \itt is lost, or we can say the theory in no longer \emph{adequate} \cite{alti:lics99}.

\begin{definition}\label{adequate}
A type theory has the $\N$-canonicity property if every closed term of $\N$ is definitionally equal to a numeral, i.e.\ either $0$ or in the form of $\text{suc}(\ldots)$.
\end{definition}

\begin{theorem}\label{noncanonical}
If we introduce functional extensionality into \itt, the $\N$-canonicity property is lost.
\end{theorem}

\begin{proof} %[Non-canonical construction]
Suppose we define two functions of type $\N \to \N$

$$\text{id} \defeq \lambda x \to x~\text{and} ~\text{id}' \defeq \lambda x \to x + 0$$

where $+$ is defined recursively as

\begin{align*}
0 + n &\defeq n \\
(\text{suc} ~m) + n &\defeq \text{suc} ~(m + n)
\end{align*}

The propositional equality $p: \forall (x : \N) \to \text{id}(x) = \text{id}'(x)$ is provable by induction on $x$. By \emph{functional extensionality}, these two functions are propositionally equal

$$\text{ext}(p) : \text{id} = \text{id}'$$

Assume $B : (\N \to \N) \to \Set$ which is defined as

$B(f) \defeq \N$

It is easy to see that $0$ is an element for $B(\text{id})$. By applying subst function (see \Cref{subst}), we can construct an element of $B(\text{id}')$ as

$$\mathsf{subst}(B,(\text{ext}(p),0)  : B(\text{id}')$$

which is also a term of $\N$ by definition of $B$.
Because the proof $\text{ext}(p)$ is not canonical, namely it can not be reduced to refl, this closed term of natural number is not reduced to either $0$ or in the form of $\text{suc}(\ldots)$.

In fact, with this term, we can construct irreducible terms of arbitrary type $A$ by a
mapping $f : \N \to A$.
\end{proof}

%This will destroy some good features of \itt. The non-canonical terms makes definitional equality undecidable and so is type checking. The termination of type checker is not assured and programs may be non-terminating.



\item \textbf{Uniqueness of Identity Proof (UIP)}\label{UIPdetail}

%\begin{definition}\label{UIP}
%\textbf{Uniqueness of identity proofs} Any two terms of a given identity type $p,q : x =_{A} y$ are thems%elves propositionally equal $p =_{x = y} q$.
%\end{definition}


\infrule[UIP]{\Gamma \vdash A \andalso \Gamma \vdash x , y : A \andalso \Gamma \vdash p, q : x = y}{\Gamma \vdash \text{uip}(p,q): p = q}



UIP is not a consequence of the eliminator for the identity type $\J$ as shown in Hofmann and Streicher's groupoid interpretation of Type Theory \cite{MR1686862}. It holds if we add another eliminator $\K$ introduced by Streicher in \cite{streicherinvestigations} as follows:

%\begin{axiom}[$\K$]
%For all $x:A$ and $p: x =_A x$ we have $p=\text{refl}_{x}$.
%\end{axiom}

\infrule[$\K$]{\Gamma \vdash a : A \andalso \Gamma, x : a = a \vdash C(x) \\ \Gamma \vdash t : C(\text{refl}(a)) \andalso \Gamma \vdash p : a = a }{\Gamma \vdash \K (t,p) : C(p)}

Computation rule:
$$\K (t , \text{refl}(a)) \equiv t$$

In programming languages such as Agda and Epigram, UIP and $\K$ are provable using dependent pattern matching. We can add an Agda flag ``--without-K'' to deny pattern matching on $a = a$ if we do not accept UIP in general. 
Although UIP for arbitrary types is not derivable, types equipped with decidable equality have the property UIP as shown by Michael Hedberg \cite{hed:98}.
A construction of the proof can be found in \cite{NisseHedberg}.

In \hott, an \emph{h-set} is a type which has UIP e.g. $\N$ (See \Cref{hott}).
%As we mentioned before, we would like to interpret types as groupoids or higher groupoids instead of sets, UIP does not hold in general. A type $A$ is a \textbf{set} (or h-set in \hott) if UIP holds for it.


%Another characterisation of a set in Type Theory is given by Hedberg's Theorem.
%\begin{theorem}[Hedberg]
%If $A$ has decidable equality, then $A$ is a set.
%\end{theorem}


\item \textbf{Proof irrelevance} 

%\red{Proof irrelevance refers to the principle that the choice of proofs of the same proposition is  irrelevant in arbitrary contexts}. 

In traditional \itt, there is no universe of propositions $\Prop$ which has proof irrelevance:

\infrule[proof-irr]{\Gamma \vdash P : \Prop \andalso \Gamma \vdash p,q : P}{\Gamma \vdash p \equiv q : P}

We usually use $\Set$ instead which does not automatically give us a proof that $(p, q : P) \to p = q$.


An example of \itt extended with $\Prop$ is the metatheory of Altenkirch's setoid model (see \Cref{setoidmodel}).


In \hott, $\Prop$ is usually treated as the universe of h-propositions which are types of h-level 1 (see \Cref{hottinterpretation}). One can think of h-propositions as the sets which have the proof-irrelevance property, hence 

$$\HProp = \Sigma (A : \Set) ~((a, b : A) \to a = b)$$.

 It is different from a universe of propositions because not every set that behaves like a proposition must be in $\Prop$, while it is the case for $\HProp$. 


If we have proof irrelevance, we can simply define identity types for sets as $x = y : \Prop$ and UIP is provable.


\item \textbf{Propositional extensionality} 


\begin{equation}
\forall P, Q : \Prop \to (P \iff Q) \to (P = Q)
\end{equation}

Propositional equality between two propositions is given by logical equivalence. Note that this only make senses if there is a universe $\Prop$.

\item \textbf{Quotient types} 

A quotient type is a type formed by redefining its equality by a given equivalence relation on it. It is the main topic of this thesis and is discussed in detail in \Cref{qt}.

\item \textbf{Univalence}

Univalence is an extensional principle from homotopy theory which is an axiom in \hott. 
It states:

Given any two types $A,B$, the canonical mapping $(A = B) \to (A \simeq B)$ is an equivalence.

Equivalence can be thought of a refinement of isomorphism in higher categories. The notions of \hott are discussed in \Cref{hott}.
Propositional extensionality is just the univalence for propositions.
\end{itemize}

\subsection{Conservativity of TT$_E$ over TT$_I$ with extensional concepts}

In \ett where we accept equality reflection and UIP, many extensional concepts are derivable, for example functional extensionality is derivable from equality reflection with $\eta$-rule for $\Pi$-types, see \Cref{prf:ertofe}. Compared to \itt it seems to be more appealing to mathematicians who are more familiar with Set Theory. However type checking is undecidable which has been formally proved by Hofmann in \cite{hof:phd}. This makes \itt more favourable, so adding extensional principles into \itt  
is one of the most important topics in Type Theory. It is preferable if the decidability of type-checking and canonicity are not sacrificed. 

The following theorem proved by Hofmann in \cite{hof:95:con} states that TT$_E$ is conservative over TT$_I$ with functional extensionality and uniqueness of identity proofs added. $\|\_\|$ is an interpretation of TT$_I$ into TT$_E$ and the judgements are differentiated by the subscript of $\vdash$.

\begin{theorem}
If $\Gamma \vdash_I A : \Set$ and $\| \Gamma \| \vdash_E a : \| A \|$ for some $a$ then there exists $a'$ such that $\Gamma \vdash_I a' : A$
\end{theorem}


Briefly speaking it is proved by using a model $\mathbf{Q}$ of TT$_I$, for example categories with families (see \Cref{cwf:def}) in the sense of Dybjer which is also a model of TT$_E$ due to the mapping $\|\_\|$ discussed above. The interpretation of the term $a$ in this model gives a term of type $A$ by fullness in TT$_I$, hence $a'$. The detailed proof can be found in \cite{hof:95:con}. In the model $\mathbf{Q}$, types and contexts are propositionally equal if they are isomorphic, which becomes definitional equal in TT$_E$. The proof is also applied to quotient types which has been shown in \cite{hof:phd}.
However, the proof is non-constructive i.e. it does not provide an algorithm to compute the term $a'$.








% intuitionism
% There is another question, whether mathematics is a collection of patterns and laws which is observed, or it is a system created and built by people to explain the patterns and laws in the world. I think people prefer the second answer usually accept the type theory more easily, although most people (probably 99.9 percent) prefer the first one. When we learn what is natural numbers, we learn it as "numbers like 1, 2, 3 ,4 and perhaps 0", the commutative law, associate law are axioms because there is no way to prove it if we introduce it in this manner. We are convinced by some examples like "2 + 3 = 3 + 2" and we find it works for most of the cases then we accept it by observations. It is some methods physicians used a lot -- to conclude some laws from a number of facts. It is a proper method for physicians because what they research on is world can only be observed. However for mathematics, even though it is applied to the real world, it is a system completely created by people. People used their fingers to count, wrote symbols for results, even though it was very shallow it is obviously a aritificial system. People extend 


% Type theory is strongly connected with computation theory.
% Set

% Type theory has fewer axioms, simpler model than set theory which has mutual foudations: logic and axioms.




%although the absence of \emph{principle of excluded middle} in intuitionistic logic makes some mathematicians hard to accept. There is a very good talk given by Andrej Bauer in IAS called "Five Stages of Accepting Constructive Mathematics'' online \footnote{available on Youtube}.



%is worth more studying. It is more close to program construction and from a computer scientist's point of view, it is very natural to accept intuitionistic logic. 


\section{An \itt with $\Prop$}\label{ittprop}

Altenkirch has introduced an extension of \itt by a universe of proof-irrelevant propositions and $\eta$-rules for $\Pi$-types and $\Sigma$-types \cite{alti:lics99}. It is used as a metatheory for his setoid model (see \Cref{models}).

The proof-irrelevant universe of propositions $\Prop$ is a subuniverse of  $\Set$ i.e.\ $p : \Prop$ implies $p : \Set$. It only contains sets with at most one inhabitant:

\infrule[proof-irr]{\Gamma \vdash P : \Prop \andalso \Gamma \vdash p,q : P}{\Gamma \vdash p \equiv q : P}

We also introduce $\top, \bot : \Prop$ as basic propositions which are similar to the unit types and empty types, namely we have $tt : \top$, and $\text{abort}(e) : A$ for any type $A$ and any $e : \bot$.

Notice that it is not a definition of types, which means that given a
proof that all inhabitants of it are definitionally equal we cannot
conclude that a type is of type \textbf{Prop}.

The propositional universe is closed under $\Pi$-types and $\Sigma$-types:

\infrule[$\Pi$-Prop]{\Gamma \vdash A : \Set \andalso \Gamma, x : A \vdash P : \Prop}
{\Gamma \vdash \Pi~ (x : A) ~ P : \Prop}


\infrule[$\Sigma$-Prop]{\Gamma \vdash P : \Prop \andalso \Gamma,x : P \vdash Q : \Prop}
{\Gamma \vdash \Sigma ~(x : P) ~ Q : \Prop}

%We may also use shorthand notation for $\Pi$-types, for example $(x:A) \to P$ or $\forall (x : A) \to P$, $P \wedge Q$ if $Q$ does not depend on $P$.


The metatheory is then proved to be:

\begin{itemize}
\item Decidable. The definitional equality is decidable, hence type checking is decidable.

\item Consistent. Not all types are inhabited and not all well typed definitional equalities hold. 

\item $\N$-canonical. All terms of type $\N$ are reducible to numerals.
\end{itemize}

The proof can be found in \cite{alti:lics99}.


\section{Homotopy Type Theory}\label{hott}

\hott (HoTT) refers to a new interpretation of intensional \mltt
into \emph{abstract} homotopy theory.
It accepts Vladimir Voevodsky's \textbf{univalence axiom} and a new schema to define types called \emph{higher inductive types}, which make many extensional concepts derivable including quotient types.


\subsection{Homotopical interpretation}\label{hottinterpretation}

Types are usually interpreted as sets in \mltt, but the identity type of types enforces a more sophisticated structure on types compared to the one on sets due to the missing Axiom $\mathsf{K}$ that asserts that all inhabitants are equal to the only constructor $\mathsf{refl}$. 

Inspired by the groupoid model of (intensional) Martin-Löf type theory due to Hofmann and Streicher, Awodey, Warren \cite{awodey-warren} and Voevodsky \cite{VV} developed \hott which is a homotopic interpretation of \mltt.

In \hott, types are regarded as spaces (or higher groupoids) instead of sets, terms are "points" of types. A function $f : A \to B$ is a continuous map between spaces $A$ and $B$.

\begin{itemize}
\item Types are interpreted as spaces. $a : A$ can be viewed as $a$ being
  a point of space $A$.
\item Terms are continuous functions, for example, $f : A \rightarrow B$ is a
  continuous function between spaces and it is equivalent to say that $a$ is
  a point of the space or $a : 1 \rightarrow A$ is a continuous function.
\item Identity types are path spaces.
\item Identity types of identity types are homotopies (if a path is considered as a continuous function $p : [0,1] \rightarrow X$).
\item Identity types of identity types of identity types and more iterated identity types are 3-homotopies, 4-homotopies etc. They form an infinite structure called \og in higher category theory.
\end{itemize}

\begin{remark}
It has to be emphasised that notions like space are purely homotopical, in other words, there are no topological notions like open sets in \hott. 
\end{remark}

%Therefore it is more appropriate to interpret types as \og instead of spaces. 

\subsection{Types as weak $\omega$-groupoids}\label{wogintro}

We can also interpret types as \textbf{\wog}.
The notion of \ogs is a generalisation of groupoid which has infinite levels of "isomorphisms" corresponding to the infinite tower of iterated identity types, i.e.\ the identity type of identity type, the identity type of identity type of identity type etc.

Formally speaking, a \wogs (or weak $\infty$-groupoid) is a weak $\omega$-category where all $k$-morphisms between $(k - 1)$-morphisms for all $k \in \N$ are equivalences. 

An ordinary category only has objects and morphisms. A 2-category includes 2-morphisms between the 1-morphisms and equalities in ordinary category are replaced by explicit arrows. We can continue this generalisation up to $n$-morphisms between $(n-1)$-morphisms which gives an n-category. An $\omega$-category is an infinite generalisation of this. Objects are also called $0$-cells, morphisms between objects are called $1$-cells, and morphisms between $n$-cells are called $(n+1)$-cells.

An equivalence is a morphism which is invertible up to all higher equivalences.
The notion of equivalence can be seen as a refinement of isomorphism in a setting without UIP \cite{txa:csl}. 
In the higher-categorical setting, equivalence can be thought of as arising from isomorphisms by systematically replacing equalities by higher cells (morphisms).
For example, an equivalence 
between two objects $A$ and $B$ in a 2-category is a morphism $f : A \rightarrow B$ which has a
corresponding inverse morphism $ g : B \rightarrow A$, but instead of the
equalities $f ∘ g = 1_B$ and $g ∘ f = 1_A$ we have 2-cell isomorphisms $f ∘ g ≅ 1_B$ and $g ∘ f ≅ 1_A$. In an $\omega$-category, these later isomorphisms are equivalences again.
These equivalences are \emph{weak} in the sense that they only hold up to higher equivalences. 
As all equivalences here are weak equivalences, from now on we just say equivalence.

In fact the \og used to model the identity types are also weak, which means that the equalities such as associativity of compositions in the $\omega$-groupoid do not hold strictly. Therefore we should call them \textbf{\wog}.

There are several versions of algebraic definitions of \wog (and also weak $\omega$-categories), one of them is the Grothendieck-Maltsiniotis $\omega$-groupoid which has been formalised in \cite{mal:gwog}.

%Although we interpret all types as \og, most types behave internally like $k$-groupoid for some $k \in \N$, which is called \textbf{truncation}. An $n$-truncated \ogs is an $n$-groupoid.

%To distinguish these structured objects interpretation from usual set-like types, we also call them \textbf{homotopy types}. 
In \hott the notion of \textbf{homotopy $n$-types} are analogous to $n$-groupoids in higher category theory. A set can be seen as a discrete space which is a $0$-groupoid. Thus a set is called a homotopy $0$-type or \textbf{h-set} which is of \textbf{homotopy level} (or h-level) $2$. It is a fact that the identity type of an $(n+1)$-type is an $n$-type, for example, the identity type of a groupoid is a set. It can be extended to lower levels: a $(\minusS 1)$-type is a proposition (\textbf{mere proposition} or \textbf{h-proposition} in \hott) and a $(\minusS 2)$-type is a contractible type. Because the identity type of a $(\minusS 2)$-type is also a $(\minusS 2)$-type, the hierarchy does not extend further.

\subsection{Univalence Axiom}\label{uaintro}

Voevodsky recognised that the homotopic interpretation is \emph{univalent} which means isomorphic types are equal, which does not usually hold in \itt. 
It is one of the fundamental axioms of \hott and is central to the Voevodsky's proposal of Univalent Foundation Project \cite{vv_uf}. 

For any two types $A, B$, there is a canonical mapping $$f : X = Y \to X \simeq Y$$ derived by induction on the identity type. The univalence axiom just claims that this mapping is an equivalence. 


It can be viewed as a strong extensionality principle which does imply functional extensionality (a Coq proof of this can be found in \cite{uafe}). 
Since isomorphic types are considered the same, all constructions and proofs can be transported between them, and it actually makes reasoning more abstract.


\subsection{Higher inductive types}\label{HITs}

In \itt, types are treated as sets and we use \emph{inductive types} to define sets which have only "points". However, in \hott, due to the enriched structures of types, inductive types can be generalised.

A more general schema to define types including higher paths is required which is higher inductive types (HITs). Higher inductive types allow constructors not only for points of the type being defined, but also for elements of its iterated identity types.
One commonly used example is the circle $\Sn^1$ (1-sphere) which can be \emph{inductively} defined as:

\begin{itemize}
\item A point $\base:\Sn^1$, and
\item A path $\lloop : {\id[\Sn^1]\base\base}$.
\end{itemize}

It is also essential to provide the elimination rule for the paths as well. Categorically speaking, it means that the functions have to be functorial on paths. That is to say, to define a function $f :\Sn^1 \rightarrow B$, assuming $f(base)=b$, we have to map $\lloop$ to an identity path $l : b = b$, namely we have an operation $\text{ap}_{f} : (x =_{\Sn^1} y) \to (f(x) =_{B} f(y))$ satisfying $\text{ap}_{f}(\lloop)=l$ .


In \hott, many extensional concepts are derivable. As we have seen, functional and propositional extensionality and are both implied by univalence, UIP for h-sets, proof irrelevance for h-propositions are also available.

Quotient types or more precisely quotient sets (because of the different interpretation of types) are also available. We will discuss them in detail in \Cref{qthott}.

For further explanation of \hott, a well-written text book elaborated by a group of mathematicians and computer scientists is available online \cite{hott}. In this thesis, we refer to it by “\emph{the} HoTT book”.

\subsection{Towards a computational interpretation of HoTT}\label{cihott}

One of the most important challenges in \hott is to build a constructive model which would give us a computational interpretation of univalence, so that the good computational properties of Type Theory are preserved \cite{bezem2013model}. 




To interpret types as weak $\omega$-groupoids, one main problem is
the complexity of its definition. The
coherence conditions are very difficult to specify so that people usually choose to use Kan simplicial sets, cubical sets to specify weak $\omega$-groupoids.
Nevertheless there are some attempts of encoding \wog in Type Theory. 
 A syntactic approach has been implemented in Agda by the author, Altenkirch and Ryp\'{a}\v{c}ek (see \Cref{wog}).

It is much simpler to interpret types as \emph{Kan simplicial sets}.
Voevodsky's univalent model \cite{klv:ssetmodel} is based on Kan simplicial sets. 
There is a concise introduction written by Streicher \cite{DBLP:dblp_journals/japll/Streicher14}. 
However the simplicial set model is not constructive as Coquand showed
that it requires classical logic in an essential way \cite{TC:sset}.
To avoid the use of classical logic, types can be interpreted as \emph{semi-simplicial sets}. We have not yet implemented the notion of semi-simplicial sets in an \itt like Agda. Some relevant discussion of it can be found online \cite{ssSet}.

Recently, Bezem, Coquand and Huber \cite{bezem2013model} proposed another model of dependent type theory 
in \emph{cubical sets}. It is expressed in a constructive metalogic which makes it a candidate for obtaining a computational interpretation of univalence. The model seems plausible but some details still need to be verified.

%Similarly, a cubical set is a presheaf on cube category, denoted as $S : \Box^{op} \rightarrow \Set$ . Different from simplicial set model, it is expressed in a constructive metalogic which makes it a more plausible model for obtaining a computational interpretation of univalence.

%\begin{remark}[Simplicial set]
%A simplicial set $X$ is a functor from $\Delta^{op}$ to $\Set$ where
%$\Delta$ is the simplex category.

%$\Delta^{op}$ is a category whose objects are non-empty totally ordered
%finite sets. The morphisms are order-preserving functions. 
%Face maps and degeneracy maps are the most important morphisms in this
%category.

%A simplex is a generalisation of a triangle to arbitrary
%dimensions. A $3$-dimensional simplex is tetrahedron and a $(k+1)$-simplex can
%be obtained by adding one point to $k$-simplex which does not lie in the
%dimension where the $k$-simplex is.

%A simplicial complex is a collection of simplices. Topologically speaking, it
%is constructed by gluing n-dimensional simplexes together. 
%\todo{show an example graph}

%A simplicial set, therefore, can be illustrated by the same graph where
%the set of points is given by $X_0$, the set of lines is $X_1$ and so
%on.
%\end{remark}

%To avoid the use of classical logic, types can be interpreted as \emph{semi-simplicial sets} which are similar to simplicial sets, but there are only face maps
%but no degeneracy maps. We can denote a semi-simplicial set as a
%functor $X : \Delta_{inj} \rightarrow \Set$. The morphisms in $\Delta_{inj}$ are not only order preserving but also injective.
%An “iterated dependency” approach is believed to solve the coherence
%issues. However we have not successfully implemented the notion of semi-simplicial sets in an \itt like Agda. Some relevant discussion of it can be found online \cite{ssSet}.
%Klaus and me were trying to implement semi-simplical set in Agda. 

\section{Summary}


The theory of types was originally invented to resolve an inconsistency in set theory in the 1900s. After that, mathematicians developed it by adding more properties, for example functions as primitive types, dependent sum and product types. Type theory is related to type systems in programming languages through the Curry-Howard isomorphisms, and some type theories like the simply-typed lambda calculus, Per Martin L\"{o}f's intuitionistic type theory and the calculus of constructions are used as cores of programming languages.

\mltt is one of the most modern type theories which is closely related to constructive \maths and computer science. It is a formal system given by a sequence of rules written as derivations of judgements. Because of the Curry-Howard isomorphism and dependent types, it is also a system for intuitionistic logic. This means that we can do constructive reasoning by constructing programs. From a mathematician's point of view, this provides computer-aided formal reasoning. From a a programmer's point of view, this provides program verification in itself and a more expressive way to write specifications for programs. Programming languages like Agda, Coq or Epigram exploit these properties.

The intensional version of \mltt has decidable type checking which is essential for a programming language. Agda is a language based on this theory providing numerous features supporting mathematical constructions and reasoning. It is widely used in academia by theoretical computer scientists and mathematicians, for example the \hott community. 

Despite the good properties of \itt, it lacks some extensional concepts like functional extensionality and quotient types. Much research has been done to add them into Type Theory without losing the computational properties. This thesis is one attempt in this direction.

Finally we discussed \hott where many extensional concepts including quotient types (see \Cref{qthott}) are available. 
We briefly compared different models of \hott where types are interpreted as different forms of \wog. However only constructive models can possibly provide computational interpretations of univalence. It is still an open problem to find such a computational interpretation, but a potential solution could be the cubical set model.







